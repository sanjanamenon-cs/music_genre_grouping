{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽµ Music Genre Clustering - PCA Analysis\n",
    "\n",
    "## Principal Component Analysis - Deep Mathematical Dive\n",
    "\n",
    "**Project:** Dimensionality Reduction and Visualization  \n",
    "**Dataset:** GTZAN (1,000 songs, 10 genres)  \n",
    "**Author:** Vedant  \n",
    "**Date:** October 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook Overview\n",
    "\n",
    "This notebook covers:\n",
    "1. PCA mathematical foundations (eigendecomposition)\n",
    "2. Covariance matrix construction\n",
    "3. Variance explained calculation (2D: 90.51%, 3D: 99.81%)\n",
    "4. 2D and 3D visualizations\n",
    "5. Projection interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mathematical Foundation of PCA\n",
    "\n",
    "### 1.1 Problem Statement\n",
    "\n",
    "Given data matrix $X \\in \\mathbb{R}^{n \\times d}$ (n=1000 songs, d=5 features):\n",
    "\n",
    "**Goal:** Find orthogonal directions that maximize variance\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 Covariance Matrix\n",
    "\n",
    "For standardized data (mean=0):\n",
    "\n",
    "$$\\Sigma = \\frac{1}{n-1} X^T X \\in \\mathbb{R}^{5 \\times 5}$$\n",
    "\n",
    "$$\\Sigma = \\begin{bmatrix}\n",
    "\\text{Var}(tempo) & \\text{Cov}(tempo, energy) & \\cdots & \\text{Cov}(tempo, danceability) \\\\\n",
    "\\text{Cov}(energy, tempo) & \\text{Var}(energy) & \\cdots & \\text{Cov}(energy, danceability) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\text{Cov}(danceability, tempo) & \\cdots & \\cdots & \\text{Var}(danceability)\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "**Properties:**\n",
    "- Symmetric: $\\Sigma = \\Sigma^T$\n",
    "- Positive semi-definite\n",
    "- Real eigenvalues and eigenvectors\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3 Eigendecomposition\n",
    "\n",
    "Solve eigenvalue equation:\n",
    "\n",
    "$$\\Sigma v = \\lambda v$$\n",
    "\n",
    "Where:\n",
    "- $\\lambda_1, \\lambda_2, ..., \\lambda_5$ = Eigenvalues (variances along principal axes)\n",
    "- $v_1, v_2, ..., v_5$ = Eigenvectors (principal component directions)\n",
    "- Ordered: $\\lambda_1 \\geq \\lambda_2 \\geq ... \\geq \\lambda_5$\n",
    "\n",
    "---\n",
    "\n",
    "### 1.4 Variance Explained\n",
    "\n",
    "**Total variance:**\n",
    "$$\\text{Total Var} = \\sum_{i=1}^{5} \\lambda_i = \\text{trace}(\\Sigma)$$\n",
    "\n",
    "**Variance explained by PC $i$:**\n",
    "$$\\text{Var}_{PC_i} = \\frac{\\lambda_i}{\\sum_{j=1}^{5} \\lambda_j} \\times 100\\%$$\n",
    "\n",
    "**Cumulative variance (2D):**\n",
    "$$\\text{Var}_{2D} = \\frac{\\lambda_1 + \\lambda_2}{\\sum_{j=1}^{5} \\lambda_j} \\times 100\\% = 90.51\\%$$\n",
    "\n",
    "**Cumulative variance (3D):**\n",
    "$$\\text{Var}_{3D} = \\frac{\\lambda_1 + \\lambda_2 + \\lambda_3}{\\sum_{j=1}^{5} \\lambda_j} \\times 100\\% = 99.81\\%$$\n",
    "\n",
    "---\n",
    "\n",
    "### 1.5 Projection Formula\n",
    "\n",
    "**2D Projection:**\n",
    "\n",
    "$$Z = X W \\in \\mathbb{R}^{1000 \\times 2}$$\n",
    "\n",
    "Where $W = [v_1 | v_2] \\in \\mathbb{R}^{5 \\times 2}$ (first 2 eigenvectors)\n",
    "\n",
    "For each song:\n",
    "$$z_i = \\begin{bmatrix} PC1_i \\\\ PC2_i \\end{bmatrix} = \\begin{bmatrix} x_i^T v_1 \\\\ x_i^T v_2 \\end{bmatrix}$$\n",
    "\n",
    "**3D Projection:**\n",
    "$$Z = X W \\in \\mathbb{R}^{1000 \\times 3}$$\n",
    "\n",
    "Where $W = [v_1 | v_2 | v_3] \\in \\mathbb{R}^{5 \\times 3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Utilities\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"âœ… Libraries loaded successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "features_df = pd.read_csv('data/processed/kmeans_cluster_assignments.csv')\n",
    "feature_cols = ['tempo', 'energy', 'loudness', 'valence', 'danceability']\n",
    "\n",
    "# Load scaler\n",
    "scaler = joblib.load('models/scaler.pkl')\n",
    "\n",
    "# Get standardized features\n",
    "X = features_df[feature_cols].values\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET LOADED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Shape: {X_scaled.shape}\")\n",
    "print(f\"Features (d): {len(feature_cols)}\")\n",
    "print(f\"Samples (n): {X_scaled.shape[0]}\")\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Step-by-Step PCA Implementation\n",
    "\n",
    "### Step 1: Compute Covariance Matrix\n",
    "\n",
    "$$\\Sigma = \\frac{1}{n-1} X^T X$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute covariance matrix manually\n",
    "n = X_scaled.shape[0]\n",
    "cov_matrix = (X_scaled.T @ X_scaled) / (n - 1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COVARIANCE MATRIX\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "cov_df = pd.DataFrame(cov_matrix, columns=feature_cols, index=feature_cols)\n",
    "print(cov_df)\n",
    "\n",
    "# Verify: should be close to identity matrix (standardized data)\n",
    "print(\"\\nâœ“ Check: Diagonal elements should be â‰ˆ 1.0 (variances of standardized features)\")\n",
    "print(f\"  Diagonal: {np.diag(cov_matrix)}\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(cov_df, \n",
    "            annot=True, \n",
    "            fmt='.3f',\n",
    "            cmap='coolwarm',\n",
    "            center=0,\n",
    "            square=True,\n",
    "            linewidths=1,\n",
    "            cbar_kws={\"label\": \"Covariance\"},\n",
    "            vmin=-1,\n",
    "            vmax=1,\n",
    "            ax=ax)\n",
    "\n",
    "ax.set_title('Covariance Matrix of Standardized Features', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Eigendecomposition\n",
    "\n",
    "$$\\Sigma v_i = \\lambda_i v_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# Sort in descending order\n",
    "idx = eigenvalues.argsort()[::-1]\n",
    "eigenvalues = eigenvalues[idx]\n",
    "eigenvectors = eigenvectors[:, idx]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EIGENDECOMPOSITION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nEigenvalues (variances along principal axes):\")\n",
    "for i, eigenval in enumerate(eigenvalues, 1):\n",
    "    print(f\"  Î»{i}: {eigenval:.6f}\")\n",
    "\n",
    "print(f\"\\nSum of eigenvalues: {eigenvalues.sum():.6f}\")\n",
    "print(f\"Trace of Î£: {np.trace(cov_matrix):.6f}\")\n",
    "print(f\"âœ“ Check: Sum(Î») â‰ˆ Trace(Î£) = {len(feature_cols)} (dimension)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EIGENVECTORS (Principal Component Directions)\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "eigenvectors_df = pd.DataFrame(\n",
    "    eigenvectors,\n",
    "    index=feature_cols,\n",
    "    columns=[f'PC{i}' for i in range(1, 6)]\n",
    ")\n",
    "print(eigenvectors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate Variance Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variance explained\n",
    "total_variance = eigenvalues.sum()\n",
    "variance_explained = (eigenvalues / total_variance) * 100\n",
    "cumulative_variance = np.cumsum(variance_explained)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VARIANCE EXPLAINED ANALYSIS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "variance_df = pd.DataFrame({\n",
    "    'PC': [f'PC{i}' for i in range(1, 6)],\n",
    "    'Eigenvalue (Î»)': eigenvalues,\n",
    "    'Variance Explained (%)': variance_explained,\n",
    "    'Cumulative Variance (%)': cumulative_variance\n",
    "})\n",
    "\n",
    "print(variance_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nðŸ“Š 2D PCA:\")\n",
    "print(f\"   PC1: {variance_explained[0]:.2f}%\")\n",
    "print(f\"   PC2: {variance_explained[1]:.2f}%\")\n",
    "print(f\"   Total (2D): {cumulative_variance[1]:.2f}% âœ…\")\n",
    "\n",
    "print(f\"\\nðŸ“Š 3D PCA:\")\n",
    "print(f\"   PC1: {variance_explained[0]:.2f}%\")\n",
    "print(f\"   PC2: {variance_explained[1]:.2f}%\")\n",
    "print(f\"   PC3: {variance_explained[2]:.2f}%\")\n",
    "print(f\"   Total (3D): {cumulative_variance[2]:.2f}% âœ…\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Information Loss:\")\n",
    "print(f\"   2D: {100 - cumulative_variance[1]:.2f}% lost\")\n",
    "print(f\"   3D: {100 - cumulative_variance[2]:.2f}% lost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize variance explained\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scree plot\n",
    "ax1.bar(range(1, 6), variance_explained, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "ax1.plot(range(1, 6), variance_explained, 'ro-', linewidth=2, markersize=8)\n",
    "ax1.axhline(y=variance_explained.mean(), color='red', linestyle='--', \n",
    "            linewidth=2, label=f'Mean: {variance_explained.mean():.1f}%')\n",
    "ax1.set_xlabel('Principal Component', fontsize=12)\n",
    "ax1.set_ylabel('Variance Explained (%)', fontsize=12)\n",
    "ax1.set_title('Scree Plot - Variance Explained per PC', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(range(1, 6))\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Cumulative variance\n",
    "ax2.plot(range(1, 6), cumulative_variance, 'go-', linewidth=3, markersize=10)\n",
    "ax2.axhline(y=90, color='orange', linestyle='--', linewidth=2, label='90% threshold')\n",
    "ax2.axvline(x=2, color='blue', linestyle='--', linewidth=2, label='2D (90.51%)')\n",
    "ax2.axvline(x=3, color='purple', linestyle='--', linewidth=2, label='3D (99.81%)')\n",
    "ax2.fill_between(range(1, 6), 0, cumulative_variance, alpha=0.3, color='green')\n",
    "ax2.set_xlabel('Number of Components', fontsize=12)\n",
    "ax2.set_ylabel('Cumulative Variance Explained (%)', fontsize=12)\n",
    "ax2.set_title('Cumulative Variance Explained', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(range(1, 6))\n",
    "ax2.set_ylim([0, 105])\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Variance plots generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PCA using scikit-learn\n",
    "\n",
    "### 4.1 Fit PCA Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D PCA\n",
    "pca_2d = PCA(n_components=2, random_state=42)\n",
    "X_pca_2d = pca_2d.fit_transform(X_scaled)\n",
    "\n",
    "# 3D PCA\n",
    "pca_3d = PCA(n_components=3, random_state=42)\n",
    "X_pca_3d = pca_3d.fit_transform(X_scaled)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SKLEARN PCA RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n2D PCA:\")\n",
    "print(f\"  Shape: {X_pca_2d.shape}\")\n",
    "print(f\"  Variance explained: {pca_2d.explained_variance_ratio_ * 100}\")\n",
    "print(f\"  Total variance: {pca_2d.explained_variance_ratio_.sum() * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\n3D PCA:\")\n",
    "print(f\"  Shape: {X_pca_3d.shape}\")\n",
    "print(f\"  Variance explained: {pca_3d.explained_variance_ratio_ * 100}\")\n",
    "print(f\"  Total variance: {pca_3d.explained_variance_ratio_.sum() * 100:.2f}%\")\n",
    "\n",
    "# Add to dataframe\n",
    "features_df['pca_1'] = X_pca_2d[:, 0]\n",
    "features_df['pca_2'] = X_pca_2d[:, 1]\n",
    "features_df['pca_3d_1'] = X_pca_3d[:, 0]\n",
    "features_df['pca_3d_2'] = X_pca_3d[:, 1]\n",
    "features_df['pca_3d_3'] = X_pca_3d[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Principal Component Loadings\n",
    "\n",
    "**Loadings** = Eigenvector components (how much each original feature contributes to each PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get loadings (components)\n",
    "loadings_2d = pca_2d.components_.T * np.sqrt(pca_2d.explained_variance_)\n",
    "loadings_3d = pca_3d.components_.T * np.sqrt(pca_3d.explained_variance_)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PRINCIPAL COMPONENT LOADINGS (2D)\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "loadings_2d_df = pd.DataFrame(\n",
    "    loadings_2d,\n",
    "    index=feature_cols,\n",
    "    columns=['PC1', 'PC2']\n",
    ")\n",
    "print(loadings_2d_df)\n",
    "\n",
    "# Visualize loadings\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(feature_cols))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, loadings_2d[:, 0], width, label='PC1', alpha=0.8, edgecolor='black')\n",
    "ax.bar(x + width/2, loadings_2d[:, 1], width, label='PC2', alpha=0.8, edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Feature', fontsize=12)\n",
    "ax.set_ylabel('Loading', fontsize=12)\n",
    "ax.set_title('Principal Component Loadings (2D)', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(feature_cols, rotation=45, ha='right')\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Loadings plot generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Principal Components\n",
    "\n",
    "Analyze what each PC represents based on loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PRINCIPAL COMPONENT INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i in range(2):\n",
    "    print(f\"\\nðŸŽ¯ PC{i+1} ({pca_2d.explained_variance_ratio_[i]*100:.2f}% variance):\")\n",
    "    \n",
    "    # Get absolute loadings\n",
    "    abs_loadings = np.abs(loadings_2d[:, i])\n",
    "    sorted_idx = abs_loadings.argsort()[::-1]\n",
    "    \n",
    "    print(\"   Top contributing features:\")\n",
    "    for idx in sorted_idx[:3]:\n",
    "        feature = feature_cols[idx]\n",
    "        loading = loadings_2d[idx, i]\n",
    "        direction = \"positive\" if loading > 0 else \"negative\"\n",
    "        print(f\"     â€¢ {feature}: {loading:.3f} ({direction})\")\n",
    "    \n",
    "    # Interpretation\n",
    "    dominant_feature = feature_cols[sorted_idx[0]]\n",
    "    print(f\"   Interpretation: Primarily represents '{dominant_feature}' variation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 2D Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static 2D scatter plot (Matplotlib)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# By cluster\n",
    "for cluster_id in range(10):\n",
    "    mask = features_df['kmeans_cluster'] == cluster_id\n",
    "    ax1.scatter(X_pca_2d[mask, 0], X_pca_2d[mask, 1], \n",
    "                label=f'Cluster {cluster_id}', alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax1.set_xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]*100:.2f}%)', fontsize=12)\n",
    "ax1.set_ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]*100:.2f}%)', fontsize=12)\n",
    "ax1.set_title('2D PCA - Colored by K-Means Clusters', fontsize=14, fontweight='bold')\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(y=0, color='black', linestyle='--', linewidth=0.8, alpha=0.5)\n",
    "ax1.axvline(x=0, color='black', linestyle='--', linewidth=0.8, alpha=0.5)\n",
    "\n",
    "# By genre\n",
    "genres = features_df['genre'].unique()\n",
    "for genre in genres:\n",
    "    mask = features_df['genre'] == genre\n",
    "    ax2.scatter(X_pca_2d[mask, 0], X_pca_2d[mask, 1], \n",
    "                label=genre, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax2.set_xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]*100:.2f}%)', fontsize=12)\n",
    "ax2.set_ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]*100:.2f}%)', fontsize=12)\n",
    "ax2.set_title('2D PCA - Colored by Original Genres', fontsize=14, fontweight='bold')\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=0, color='black', linestyle='--', linewidth=0.8, alpha=0.5)\n",
    "ax2.axvline(x=0, color='black', linestyle='--', linewidth=0.8, alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š 2D scatter plots generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 3D Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static 3D plot (Matplotlib)\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot by cluster\n",
    "for cluster_id in range(10):\n",
    "    mask = features_df['kmeans_cluster'] == cluster_id\n",
    "    ax.scatter(X_pca_3d[mask, 0], X_pca_3d[mask, 1], X_pca_3d[mask, 2],\n",
    "               label=f'Cluster {cluster_id}', alpha=0.6, s=30, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca_3d.explained_variance_ratio_[0]*100:.2f}%)', fontsize=12)\n",
    "ax.set_ylabel(f'PC2 ({pca_3d.explained_variance_ratio_[1]*100:.2f}%)', fontsize=12)\n",
    "ax.set_zlabel(f'PC3 ({pca_3d.explained_variance_ratio_[2]*100:.2f}%)', fontsize=12)\n",
    "ax.set_title('3D PCA Visualization (99.81% variance)', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.legend(loc='upper right', fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š 3D scatter plot generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive 3D plot (Plotly)\n",
    "fig = px.scatter_3d(\n",
    "    features_df,\n",
    "    x='pca_3d_1',\n",
    "    y='pca_3d_2',\n",
    "    z='pca_3d_3',\n",
    "    color='kmeans_cluster',\n",
    "    hover_data=['filename', 'genre'],\n",
    "    labels={\n",
    "        'pca_3d_1': f'PC1 ({pca_3d.explained_variance_ratio_[0]*100:.2f}%)',\n",
    "        'pca_3d_2': f'PC2 ({pca_3d.explained_variance_ratio_[1]*100:.2f}%)',\n",
    "        'pca_3d_3': f'PC3 ({pca_3d.explained_variance_ratio_[2]*100:.2f}%)',\n",
    "        'kmeans_cluster': 'Cluster'\n",
    "    },\n",
    "    title='Interactive 3D PCA Visualization (99.81% variance)',\n",
    "    color_continuous_scale='viridis'\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=4, opacity=0.7, line=dict(width=0.5, color='white')))\n",
    "fig.update_layout(height=700, showlegend=True)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Interactive 3D plot generated!\")\n",
    "print(\"ðŸ’¡ Tip: Rotate, zoom, and hover over points for details\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Reconstruction Error Analysis\n",
    "\n",
    "### Measure information loss from dimensionality reduction\n",
    "\n",
    "**Reconstruction error:**\n",
    "$$\\text{Error} = \\|X - \\hat{X}\\|_F^2$$\n",
    "\n",
    "Where $\\hat{X}$ is reconstructed from PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct from 2D\n",
    "X_reconstructed_2d = pca_2d.inverse_transform(X_pca_2d)\n",
    "reconstruction_error_2d = np.mean((X_scaled - X_reconstructed_2d) ** 2)\n",
    "\n",
    "# Reconstruct from 3D\n",
    "X_reconstructed_3d = pca_3d.inverse_transform(X_pca_3d)\n",
    "reconstruction_error_3d = np.mean((X_scaled - X_reconstructed_3d) ** 2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECONSTRUCTION ERROR ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nMean Squared Error (MSE):\")\n",
    "print(f\"  2D reconstruction: {reconstruction_error_2d:.6f}\")\n",
    "print(f\"  3D reconstruction: {reconstruction_error_3d:.6f}\")\n",
    "\n",
    "print(f\"\\nRelative Error:\")\n",
    "print(f\"  2D: {reconstruction_error_2d / np.mean(X_scaled**2) * 100:.2f}%\")\n",
    "print(f\"  3D: {reconstruction_error_3d / np.mean(X_scaled**2) * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\nConclusion:\")\n",
    "print(f\"  2D captures {100 - (100 - pca_2d.explained_variance_ratio_.sum()*100):.2f}% of variance\")\n",
    "print(f\"  3D captures {100 - (100 - pca_3d.explained_variance_ratio_.sum()*100):.2f}% of variance\")\n",
    "print(f\"  âœ… 3D is almost perfect representation (99.81% variance)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save PCA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PCA models\n",
    "joblib.dump(pca_2d, 'models/pca_2d_model.pkl')\n",
    "joblib.dump(pca_3d, 'models/pca_3d_model.pkl')\n",
    "\n",
    "# Save transformed data\n",
    "features_df.to_csv('data/processed/features_with_pca.csv', index=False)\n",
    "\n",
    "# Save variance analysis\n",
    "variance_df.to_csv('data/processed/pca_variance_analysis.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FILES SAVED\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nâœ… models/pca_2d_model.pkl\")\n",
    "print(\"âœ… models/pca_3d_model.pkl\")\n",
    "print(\"âœ… data/processed/features_with_pca.csv\")\n",
    "print(\"âœ… data/processed/pca_variance_analysis.csv\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "### PCA Results\n",
    "\n",
    "**2D Projection (90.51% variance):**\n",
    "- PC1: 51.32% variance\n",
    "- PC2: 39.19% variance\n",
    "- Information loss: 9.49%\n",
    "- Suitable for visualization\n",
    "\n",
    "**3D Projection (99.81% variance):**\n",
    "- PC1: 51.32% variance\n",
    "- PC2: 39.19% variance\n",
    "- PC3: 9.30% variance\n",
    "- Information loss: 0.19%\n",
    "- Almost perfect representation\n",
    "\n",
    "**Why Variance Changes:**\n",
    "1. Each PC captures **additional** orthogonal variance\n",
    "2. Cumulative variance **increases** with more dimensions\n",
    "3. PC1 captures most variance (maximum spread)\n",
    "4. Remaining PCs capture progressively less\n",
    "\n",
    "**Mathematical Insight:**\n",
    "$$\\text{Var}_{2D} = \\frac{\\lambda_1 + \\lambda_2}{\\sum \\lambda_i} = 90.51\\%$$\n",
    "$$\\text{Var}_{3D} = \\frac{\\lambda_1 + \\lambda_2 + \\lambda_3}{\\sum \\lambda_i} = 99.81\\%$$\n",
    "\n",
    "### Next Steps\n",
    "Complete evaluation with all metrics (Notebook 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
